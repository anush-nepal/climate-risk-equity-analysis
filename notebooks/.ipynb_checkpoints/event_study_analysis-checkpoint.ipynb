{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0444b38-6191-464e-a093-7c63318e3c06",
   "metadata": {},
   "source": [
    "# Climate Risk Premium Analysis: Event Study Analysis\n",
    "\n",
    "**Project**: Analyzing Climate Risk Premiums in US Equity Markets  \n",
    "**Notebook**: 3. Event Study Analysis  \n",
    "**Author**: Anush Nepal  \n",
    "\n",
    "## Objective\n",
    "Test the statistical significance of market reactions to climate events using formal event study methodology: - **Hypothesis testing**: Are returns during climate events significantly different from normal periods?  \n",
    "- **Abnormal return calculation**: Measure excess returns beyond normal market expectations  \n",
    "- **Sector-specific analysis**: Test if different sectors respond differently to climate events  \n",
    "- **Statistical confidence**: Determine if observed patterns are statistically meaningful\n",
    "\n",
    "Event study analysis is the standard methodology in finance research for measuring market reactions to specific events. We'll test whether climate events create statistically significant abnormal returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd9c51-768b-4ec6-8fc8-fefbd764c538",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries & Loading Data\n",
    "Loading our processed datasets and statistical testing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c668fc5c-6ef9-4476-a06a-809d2404908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Analysis date: 2025-08-22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp, ttest_ind, normaltest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc251cb-61c7-489b-9823-cbeeb86d9397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed datasets...\n",
      "Main dataset loaded: (90424, 18)\n",
      "Event analysis data loaded: (4319, 23)\n",
      "Sector returns loaded: (2010, 4)\n",
      "Date range: 2017-01-04 to 2024-12-30\n",
      "Climate events in dataset: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading processed datasets...\")\n",
    "\n",
    "df = pd.read_csv('../data/processed/stock_data_with_features.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "event_df = pd.read_csv('../data/processed/climate_event_analysis.csv')\n",
    "event_df['Date'] = pd.to_datetime(event_df['Date'])\n",
    "event_df['Event_Date'] = pd.to_datetime(event_df['Event_Date'])\n",
    "\n",
    "sector_returns = pd.read_csv('../data/processed/sector_daily_returns.csv')\n",
    "sector_returns['Date'] = pd.to_datetime(sector_returns['Date'])\n",
    "\n",
    "print(f\"Main dataset loaded: {df.shape}\")\n",
    "print(f\"Event analysis data loaded: {event_df.shape}\")\n",
    "print(f\"Sector returns loaded: {sector_returns.shape}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "print(f\"Climate events in dataset: {event_df['Event_Name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994ed3-b1b9-4597-8100-3eccc7c7d539",
   "metadata": {},
   "source": [
    "## Statistical Hypothesis Testing\n",
    "Testing the central hypothesis **Do climate events create abnormal returns that are statistically different from normal market performance?**\n",
    "### Methodology\n",
    "- **Null Hypothesis (H0)**: Climate events have no effect on stock returns (mean return = 0)\n",
    "- **Alternative Hypothesis (H1)**: Climate events create abnormal returns (mean return != 0)\n",
    "- **Statistical Test**: One-sample t-test comparing event period returns to zero\n",
    "- **Significance Level**: Î± = 0.05 (95% confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63249ead-83e6-4e67-a6fb-0895349565a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Test 1: Event Returns vs Zero\n",
      "\n",
      "Sample size: 4,319 observations\n",
      "Mean return during events: 0.001662 (0.1662%)\n",
      "Standard deviation: 0.017521\n",
      "\n",
      "T-test Results:\n",
      "T-statistic: 6.2347\n",
      "P-value: 0.000000\n",
      "Significant at 5% level: Yes\n",
      "\n",
      "95% Confidence Interval:\n",
      "[0.001139, 0.002185]\n",
      "In percentage terms: [0.1139%, 0.2185%]\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical Test 1: Event Returns vs Zero\")\n",
    "print()\n",
    "event_returns = event_df['Daily_Return'].dropna()\n",
    "n_observations = len(event_returns)\n",
    "mean_return = event_returns.mean()\n",
    "std_return = event_returns.std()\n",
    "print(f\"Sample size: {n_observations:,} observations\")\n",
    "print(f\"Mean return during events: {mean_return:.6f} ({mean_return*100:.4f}%)\")\n",
    "print(f\"Standard deviation: {std_return:.6f}\")\n",
    "\n",
    "t_statistic, p_value = ttest_1samp(event_returns, 0) # One-sample t-test (Are event returns significatnly different from 0?)\n",
    "print(f\"\\nT-test Results:\")\n",
    "print(f\"T-statistic: {t_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print(f\"Significant at 5% level: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "confidence_level = 0.95 # Calculating confidence interval\n",
    "degrees_freedom = n_observations - 1\n",
    "t_critical = stats.t.ppf((1 + confidence_level) / 2, degrees_freedom)\n",
    "margin_error = t_critical * (std_return / np.sqrt(n_observations))\n",
    "ci_lower = mean_return - margin_error\n",
    "ci_upper = mean_return + margin_error\n",
    "print(f\"\\n95% Confidence Interval:\")\n",
    "print(f\"[{ci_lower:.6f}, {ci_upper:.6f}]\")\n",
    "print(f\"In percentage terms: [{ci_lower*100:.4f}%, {ci_upper*100:.4f}%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa32a1f2-47d9-463f-9982-69204952ebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Test 2: Event vs Non-Event Period Returns\n",
      "\n",
      "Event period observations: 4,319\n",
      "Normal period observations: 86,105\n",
      "\n",
      "Event periods - Mean: 0.001662 (0.1662%)\n",
      "Normal periods - Mean: 0.000545 (0.0545%)\n",
      "Difference: 0.001117 (0.1117%)\n",
      "\n",
      "Two-sample t-test results:\n",
      "T-statistic: 3.4649\n",
      "P-value: 0.000531\n",
      "Significant at 5% level: Yes\n",
      "Effect size (Cohen's d): 0.0540\n",
      "Effect interpretation: Small\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical Test 2: Event vs Non-Event Period Returns\")\n",
    "print()\n",
    "\n",
    "event_period_returns = event_df['Daily_Return'].dropna() # Separating event and non-event returns\n",
    "normal_period_returns = df[~df.index.isin(event_df.index)]['Daily_Return'].dropna()\n",
    "print(f\"Event period observations: {len(event_period_returns):,}\")\n",
    "print(f\"Normal period observations: {len(normal_period_returns):,}\")\n",
    "\n",
    "event_mean = event_period_returns.mean() # Calculating statistics for both groups\n",
    "normal_mean = normal_period_returns.mean()\n",
    "event_std = event_period_returns.std()\n",
    "normal_std = normal_period_returns.std()\n",
    "print(f\"\\nEvent periods - Mean: {event_mean:.6f} ({event_mean*100:.4f}%)\")\n",
    "print(f\"Normal periods - Mean: {normal_mean:.6f} ({normal_mean*100:.4f}%)\")\n",
    "print(f\"Difference: {(event_mean - normal_mean):.6f} ({(event_mean - normal_mean)*100:.4f}%)\")\n",
    "\n",
    "t_stat_2sample, p_val_2sample = ttest_ind(event_period_returns, normal_period_returns) # Two-sample t-test (Are event returns different from normal returns?)\n",
    "print(f\"\\nTwo-sample t-test results:\")\n",
    "print(f\"T-statistic: {t_stat_2sample:.4f}\")\n",
    "print(f\"P-value: {p_val_2sample:.6f}\")\n",
    "print(f\"Significant at 5% level: {'Yes' if p_val_2sample < 0.05 else 'No'}\")\n",
    "\n",
    "pooled_std = np.sqrt(((len(event_period_returns)-1)*event_std**2 + (len(normal_period_returns)-1)*normal_std**2) / (len(event_period_returns) + len(normal_period_returns) - 2)) # Effect size (Cohen's d)\n",
    "cohens_d = (event_mean - normal_mean) / pooled_std\n",
    "print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "print(f\"Effect interpretation: {'Small' if abs(cohens_d) < 0.2 else 'Medium' if abs(cohens_d) < 0.5 else 'Large'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2e0ae-fde6-485f-bade-1eb592a7f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
